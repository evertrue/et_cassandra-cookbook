#!/usr/bin/env bash

set -e

<% if node['et_cassandra']['cronitor']['backups_snapshot']['enabled'] -%>
/usr/local/bin/cronitor_backups_snapshot run
<% end -%>

source /etc/cassandra/snapshots.conf

let tar_retries=5
let upload_retries=5

root_dir=`dirname "<%= node['et_cassandra']['config']['data_file_directories'].first %>"`
data_dirs="<%= node['et_cassandra']['config']['data_file_directories'].join(' ') %>"
work_dir="${root_dir}/backup_work_dir"
old_pwd="$PWD"

mkdir -p "${work_dir}"

function contained_by {
  local i

  for i in "${@:2}"; do [[ "${i}" == "${1}" ]] && return 0; done
  return 1
}

# First delete all incremental backups
for data_dir in $data_dirs; do
  # The following may be over-engineering but it prevents us from accidentally
  # deleting a future keyspace named "backups" should one ever be created.
  for keyspace in `find $data_dir -maxdepth 1 -mindepth 1 -type d -exec basename {} \;`; do
    find "$data_dir"/"$keyspace" -mindepth 4 -type f -path '*/backups/*' -delete
  done
done

# Clear out old snapshots
nodetool -h localhost clearsnapshot

# Perform the snapshot and get the ID
snapshot_id=`nodetool -h localhost snapshot | \
             grep 'Snapshot directory: ' | \
             awk '{print $3}'`

# Wait 30 seconds for the snapshots to complete
sleep 30

backup_date=`date +%Y-%m-%dT%H%M%S`

let dir_index=1

for data_dir in $data_dirs; do
  for keyspace in `find $data_dir -maxdepth 1 -mindepth 1 -type d -exec basename {} \;`; do
    if contained_by "${keyspace}" "${SKIP_KEYSPACES[@]}"; then continue; fi

    if [ -n "$(find $data_dir/$keyspace -maxdepth 3 -mindepth 3 -path \*/snapshots/$snapshot_id -type d | head -n 1)" ]; then
      cd "$data_dir"

      tarball="${work_dir}/$keyspace-$dir_index.tar.gz"

      if [ -e "$tarball" ]; then
        echo "$tarball already exists! Bailing instead of overwriting it."
        exit 1
      fi

      set +e
      let try=0
      until [ $try -ge $tar_retries ]; do
        tar -czf "$tarball" "$keyspace"/*/snapshots/$snapshot_id && break
        if [ -f "${tarball}" ]; then
          rm -f "${tarball}"
        fi
        echo "tar failed. Retrying... ($try/$tar_retries)"
        let try=$[$try+1]
        sleep <%= node['et_cassandra']['snapshot']['tar_retry_secs'] %>
      done
      set -e

      if [ $try -ge $tar_retries ]; then
        echo "Could not create ${tarball} in ${tar_retries} tries. Skipping keyspace ${keyspace} in data_dir ${data_dir}."
        continue
      fi

      trap "rm -f $tarball; cd \"$old_pwd\"; exit" INT TERM EXIT

      if [ "$AWS_ACCESS_KEY_ID" ]; then
        access_key_flags="--access_key $AWS_ACCESS_KEY_ID --secret_key $AWS_SECRET_ACCESS_KEY"
      fi

      set +e
      let try=0
      until [ $try -ge $upload_retries ]; do
        s3cmd put \
          --quiet \
          ${access_key_flags} \
          --server-side-encryption \
          --region $REGION \
          "$tarball" \
          "s3://$BUCKET/cassandra/<%= node.chef_environment %>/<%= node['fqdn'] %>/snapshots/$backup_date/$keyspace-$dir_index.tar.gz" && break
        echo "S3 Upload failed. Retrying ($try/$upload_retries)"
        let try=$[$try+1]
        sleep 5
      done
      set -e

      if [ $try -ge $upload_retries ]; then
        echo "Could not upload ${tarball} in ${upload_retries} tries. Skipping keyspace ${keyspace} in data_dir ${data_dir}."
        continue
      fi

      rm -f "$tarball"

      trap - INT TERM EXIT
    else
      echo "Nothing to back up in "$data_dir"/"$keyspace"/*/snapshots/$snapshot_id"
    fi
  done
  let dir_index++
done

cd "$old_pwd"

# Clear out newly created snapshots
nodetool -h localhost clearsnapshot

<% if node['et_cassandra']['cronitor']['backups_snapshot']['enabled'] -%>
/usr/local/bin/cronitor_backups_snapshot complete
<% end -%>
